{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sCV30xyVhFbE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FIleuCAjoFD8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.9.1'"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0koUcJMJpEBD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5712 images belonging to 4 classes.\n",
            "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('input/Training',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "labels =training_set.class_indices\n",
        "print(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SH4WzfOhpKc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1311 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('input/Testing',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SAUt4UMPlhLS"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XPzPrMckl-hV"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[224, 224, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ncpqPl69mOac"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "i_-FZjn_m8gk"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding a third convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6AZeOGCvnNZn"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8GtmUlLd26Nq"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1p_Zj1Mc3Ko_"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NALksrNQpUlJ"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = Adam(learning_rate=0.003), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XUj1W4PJptta"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "179/179 [==============================] - 220s 1s/step - loss: 0.9923 - accuracy: 0.5807 - val_loss: 0.7018 - val_accuracy: 0.7300\n",
            "Epoch 2/25\n",
            "179/179 [==============================] - 213s 1s/step - loss: 0.6640 - accuracy: 0.7402 - val_loss: 0.7136 - val_accuracy: 0.7422\n",
            "Epoch 3/25\n",
            "179/179 [==============================] - 210s 1s/step - loss: 0.5565 - accuracy: 0.7890 - val_loss: 0.5651 - val_accuracy: 0.7597\n",
            "Epoch 4/25\n",
            "179/179 [==============================] - 197s 1s/step - loss: 0.4724 - accuracy: 0.8295 - val_loss: 0.4706 - val_accuracy: 0.8047\n",
            "Epoch 5/25\n",
            "179/179 [==============================] - 151s 844ms/step - loss: 0.3981 - accuracy: 0.8508 - val_loss: 0.4924 - val_accuracy: 0.7948\n",
            "Epoch 6/25\n",
            "179/179 [==============================] - 149s 829ms/step - loss: 0.3887 - accuracy: 0.8561 - val_loss: 0.4558 - val_accuracy: 0.8299\n",
            "Epoch 7/25\n",
            "179/179 [==============================] - 159s 886ms/step - loss: 0.3375 - accuracy: 0.8771 - val_loss: 0.3165 - val_accuracy: 0.8452\n",
            "Epoch 8/25\n",
            "179/179 [==============================] - 162s 903ms/step - loss: 0.3127 - accuracy: 0.8827 - val_loss: 0.4506 - val_accuracy: 0.8093\n",
            "Epoch 9/25\n",
            "179/179 [==============================] - 174s 969ms/step - loss: 0.3020 - accuracy: 0.8955 - val_loss: 0.2821 - val_accuracy: 0.8802\n",
            "Epoch 10/25\n",
            "179/179 [==============================] - 168s 936ms/step - loss: 0.2709 - accuracy: 0.8995 - val_loss: 0.2741 - val_accuracy: 0.8879\n",
            "Epoch 11/25\n",
            "179/179 [==============================] - 175s 976ms/step - loss: 0.2400 - accuracy: 0.9126 - val_loss: 0.3639 - val_accuracy: 0.8482\n",
            "Epoch 12/25\n",
            "179/179 [==============================] - 176s 984ms/step - loss: 0.2275 - accuracy: 0.9198 - val_loss: 0.3014 - val_accuracy: 0.8886\n",
            "Epoch 13/25\n",
            "179/179 [==============================] - 176s 981ms/step - loss: 0.2158 - accuracy: 0.9161 - val_loss: 0.2537 - val_accuracy: 0.9024\n",
            "Epoch 14/25\n",
            "179/179 [==============================] - 184s 1s/step - loss: 0.2213 - accuracy: 0.9177 - val_loss: 0.2726 - val_accuracy: 0.8886\n",
            "Epoch 15/25\n",
            "179/179 [==============================] - 192s 1s/step - loss: 0.1870 - accuracy: 0.9322 - val_loss: 0.4131 - val_accuracy: 0.8612\n",
            "Epoch 16/25\n",
            "179/179 [==============================] - 181s 1s/step - loss: 0.1916 - accuracy: 0.9312 - val_loss: 0.2450 - val_accuracy: 0.9077\n",
            "Epoch 17/25\n",
            "179/179 [==============================] - 174s 972ms/step - loss: 0.1712 - accuracy: 0.9442 - val_loss: 0.2148 - val_accuracy: 0.9222\n",
            "Epoch 18/25\n",
            "179/179 [==============================] - 176s 981ms/step - loss: 0.1651 - accuracy: 0.9456 - val_loss: 0.2064 - val_accuracy: 0.9367\n",
            "Epoch 19/25\n",
            "179/179 [==============================] - 166s 923ms/step - loss: 0.1825 - accuracy: 0.9352 - val_loss: 0.4029 - val_accuracy: 0.8696\n",
            "Epoch 20/25\n",
            "179/179 [==============================] - 166s 923ms/step - loss: 0.1572 - accuracy: 0.9473 - val_loss: 0.1435 - val_accuracy: 0.9458\n",
            "Epoch 21/25\n",
            "179/179 [==============================] - 181s 1s/step - loss: 0.1586 - accuracy: 0.9445 - val_loss: 0.1448 - val_accuracy: 0.9436\n",
            "Epoch 22/25\n",
            "179/179 [==============================] - 313s 2s/step - loss: 0.1436 - accuracy: 0.9471 - val_loss: 0.1622 - val_accuracy: 0.9436\n",
            "Epoch 23/25\n",
            "179/179 [==============================] - 385s 2s/step - loss: 0.1529 - accuracy: 0.9468 - val_loss: 0.1494 - val_accuracy: 0.9382\n",
            "Epoch 24/25\n",
            "179/179 [==============================] - 330s 2s/step - loss: 0.1350 - accuracy: 0.9529 - val_loss: 0.1426 - val_accuracy: 0.9497\n",
            "Epoch 25/25\n",
            "179/179 [==============================] - 328s 2s/step - loss: 0.1366 - accuracy: 0.9564 - val_loss: 0.1432 - val_accuracy: 0.9497\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x13d2ceb80a0>"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25, verbose = 1 , callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 111ms/step\n",
            "[[4.9810572e-10 1.9925607e-04 9.9980074e-01 7.5695986e-12]]\n",
            "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n",
            "['notumor']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras import utils\n",
        "test_image = utils.load_img('input/Testing/notumor/Te-no_0018.jpg', target_size = (224, 224))\n",
        "test_image = utils.img_to_array(test_image) /255.0\n",
        "test_image = np.expand_dims(test_image, axis = 0) # Convert single image to a batch.\n",
        "predicted_indice_arr = cnn.predict(test_image)\n",
        "print(predicted_indice_arr)\n",
        "prediction = np.argmax(predicted_indice_arr, axis=1)\n",
        "\n",
        "print(labels)\n",
        "final_prediction = [key for key, val in labels.items() if val == prediction[0]]\n",
        "print(final_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[0.0000000e+00 3.9215689e-03 1.8020093e-21 0.0000000e+00]]\n",
            "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n",
            "['meningioma']\n"
          ]
        }
      ],
      "source": [
        "test_image = utils.load_img('input/Testing/pituitary/Te-pi_0056.jpg', target_size = (224, 224))\n",
        "test_image = utils.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0) # Convert single image to a batch.\n",
        "predicted_indice_arr = cnn.predict(test_image) /255.0\n",
        "print(predicted_indice_arr)\n",
        "prediction = np.argmax(predicted_indice_arr, axis=1)\n",
        "\n",
        "print(labels)\n",
        "final_prediction = [key for key, val in labels.items() if val == prediction[0]]\n",
        "print(final_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[0.         0.         0.00392157 0.        ]]\n",
            "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n",
            "['notumor']\n"
          ]
        }
      ],
      "source": [
        "test_image = utils.load_img('input/Testing/glioma/Te-gl_0078.jpg', target_size = (224, 224))\n",
        "test_image = utils.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0) # Convert single image to a batch.\n",
        "predicted_indice_arr = cnn.predict(test_image) /255.0\n",
        "print(predicted_indice_arr)\n",
        "prediction = np.argmax(predicted_indice_arr, axis=1)\n",
        "\n",
        "print(labels)\n",
        "final_prediction = [key for key, val in labels.items() if val == prediction[0]]\n",
        "print(final_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n",
            "[[0.0000000e+00 3.9215689e-03 1.9855457e-23 0.0000000e+00]]\n",
            "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n",
            "['meningioma']\n"
          ]
        }
      ],
      "source": [
        "test_image = utils.load_img('input/Testing/meningioma/Te-me_0067.jpg', target_size = (224, 224))\n",
        "test_image = utils.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0) # Convert single image to a batch.\n",
        "predicted_indice_arr = cnn.predict(test_image) /255.0\n",
        "print(predicted_indice_arr)\n",
        "prediction = np.argmax(predicted_indice_arr, axis=1)\n",
        "\n",
        "print(labels)\n",
        "final_prediction = [key for key, val in labels.items() if val == prediction[0]]\n",
        "print(final_prediction)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "convolutional_neural_network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
